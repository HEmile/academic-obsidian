---
aliases:
  - RSs
subset:
  - "[[neurosymbolic learning]]"
Created: "[[17-10-2025]]"
---
This is when in typical NeSy predictor setups, a NeSy predictor properly learned the input-output problem (to 100% accuracy), but did not learn the proper concept extractor. Happens because the problem is not [[identifiable]]

Introduced in [[Not all neuro-symbolic concepts are created equal_ Analysis and mitigation of reasoning shortcuts]], but we now have a larger journal article in [[Symbol grounding in neuro-symbolic AI_ A gentle introduction to reasoning shortcuts]]


--- 
#topic 
