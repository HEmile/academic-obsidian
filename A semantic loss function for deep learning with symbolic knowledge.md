---
aliases:
  - xu2018semanticlossfunctiondeep
  - Semantic Loss
year: 2018
annotation-target:
hasTopic:
  - "[[neurosymbolic learning]]"
  - "[[probabilistic logics]]"
author:
  - "[[Jingyi Xu]]"
  - "[[Zilu Zhang]]"
  - "[[Tal Friedman]]"
  - "[[Yitao Liang]]"
  - "[[Guy Van den Broeck]]"
project: []
publishedIn: "[[ICML]]"
citeKey: xu2018semanticlossfunctiondeep
zoteroUri: zotero://select/items/@xu2018semanticlossfunctiondeep
url: https://arxiv.org/abs/1711.11157
---
How should you design a loss function to teach neural networks about background knowledge? This paper uses simple probabilistic logics to achieve this. Computationally this is hard, so they use [[probabilistic circuits]] where the structure is given by a [[knowledge compilation]] algorithm

--- 
#source/paper